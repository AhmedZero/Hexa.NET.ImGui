// ------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
// ------------------------------------------------------------------------------

using System;
using System.Runtime.CompilerServices;
using System.Runtime.InteropServices;
using HexaGen.Runtime;
using System.Numerics;
using Hexa.NET.ImGui;

namespace Hexa.NET.ImPlot
{
	public unsafe partial class ImPlot
	{

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ulong ImSumU64Ptr(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				ulong ret = ImSumU64PtrNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanFloatPtrNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, double>)vt[438])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[438])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanFloatPtr(float* values, int count)
		{
			double ret = ImMeanFloatPtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanFloatPtr(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				double ret = ImMeanFloatPtrNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanDoublePtrNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)vt[439])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[439])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanDoublePtr(double* values, int count)
		{
			double ret = ImMeanDoublePtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanDoublePtr(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImMeanDoublePtrNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanS8PtrNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)vt[440])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[440])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS8Ptr(byte* values, int count)
		{
			double ret = ImMeanS8PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS8Ptr(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImMeanS8PtrNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanU8PtrNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)vt[441])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[441])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU8Ptr(byte* values, int count)
		{
			double ret = ImMeanU8PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU8Ptr(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImMeanU8PtrNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanS16PtrNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, double>)vt[442])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[442])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS16Ptr(short* values, int count)
		{
			double ret = ImMeanS16PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS16Ptr(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				double ret = ImMeanS16PtrNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanU16PtrNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, double>)vt[443])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[443])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU16Ptr(ushort* values, int count)
		{
			double ret = ImMeanU16PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU16Ptr(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				double ret = ImMeanU16PtrNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanS32PtrNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, double>)vt[444])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[444])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS32Ptr(int* values, int count)
		{
			double ret = ImMeanS32PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS32Ptr(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				double ret = ImMeanS32PtrNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanU32PtrNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, double>)vt[445])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[445])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU32Ptr(uint* values, int count)
		{
			double ret = ImMeanU32PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU32Ptr(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				double ret = ImMeanU32PtrNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanS64PtrNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, double>)vt[446])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[446])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS64Ptr(long* values, int count)
		{
			double ret = ImMeanS64PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanS64Ptr(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				double ret = ImMeanS64PtrNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImMeanU64PtrNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, double>)vt[447])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[447])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU64Ptr(ulong* values, int count)
		{
			double ret = ImMeanU64PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImMeanU64Ptr(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				double ret = ImMeanU64PtrNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevFloatPtrNative(float* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float*, int, double>)vt[448])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[448])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevFloatPtr(float* values, int count)
		{
			double ret = ImStdDevFloatPtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevFloatPtr(ref float values, int count)
		{
			fixed (float* pvalues = &values)
			{
				double ret = ImStdDevFloatPtrNative((float*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevDoublePtrNative(double* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double*, int, double>)vt[449])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[449])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevDoublePtr(double* values, int count)
		{
			double ret = ImStdDevDoublePtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevDoublePtr(ref double values, int count)
		{
			fixed (double* pvalues = &values)
			{
				double ret = ImStdDevDoublePtrNative((double*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevS8PtrNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)vt[450])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[450])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS8Ptr(byte* values, int count)
		{
			double ret = ImStdDevS8PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS8Ptr(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImStdDevS8PtrNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevU8PtrNative(byte* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte*, int, double>)vt[451])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[451])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU8Ptr(byte* values, int count)
		{
			double ret = ImStdDevU8PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU8Ptr(ref byte values, int count)
		{
			fixed (byte* pvalues = &values)
			{
				double ret = ImStdDevU8PtrNative((byte*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevS16PtrNative(short* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short*, int, double>)vt[452])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[452])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS16Ptr(short* values, int count)
		{
			double ret = ImStdDevS16PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS16Ptr(ref short values, int count)
		{
			fixed (short* pvalues = &values)
			{
				double ret = ImStdDevS16PtrNative((short*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevU16PtrNative(ushort* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort*, int, double>)vt[453])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[453])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU16Ptr(ushort* values, int count)
		{
			double ret = ImStdDevU16PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU16Ptr(ref ushort values, int count)
		{
			fixed (ushort* pvalues = &values)
			{
				double ret = ImStdDevU16PtrNative((ushort*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevS32PtrNative(int* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int*, int, double>)vt[454])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[454])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS32Ptr(int* values, int count)
		{
			double ret = ImStdDevS32PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS32Ptr(ref int values, int count)
		{
			fixed (int* pvalues = &values)
			{
				double ret = ImStdDevS32PtrNative((int*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevU32PtrNative(uint* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, double>)vt[455])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[455])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU32Ptr(uint* values, int count)
		{
			double ret = ImStdDevU32PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU32Ptr(ref uint values, int count)
		{
			fixed (uint* pvalues = &values)
			{
				double ret = ImStdDevU32PtrNative((uint*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevS64PtrNative(long* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long*, int, double>)vt[456])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[456])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS64Ptr(long* values, int count)
		{
			double ret = ImStdDevS64PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevS64Ptr(ref long values, int count)
		{
			fixed (long* pvalues = &values)
			{
				double ret = ImStdDevS64PtrNative((long*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double ImStdDevU64PtrNative(ulong* values, int count)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong*, int, double>)vt[457])(values, count);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, int, double>)vt[457])((nint)values, count);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU64Ptr(ulong* values, int count)
		{
			double ret = ImStdDevU64PtrNative(values, count);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double ImStdDevU64Ptr(ref ulong values, int count)
		{
			fixed (ulong* pvalues = &values)
			{
				double ret = ImStdDevU64PtrNative((ulong*)pvalues, count);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ImMixU32Native(uint a, uint b, uint s)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)vt[458])(a, b, s);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<uint, uint, uint, uint>)vt[458])(a, b, s);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImMixU32(uint a, uint b, uint s)
		{
			uint ret = ImMixU32Native(a, b, s);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ImLerpU32Native(uint* colors, int size, float t)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint*, int, float, uint>)vt[459])(colors, size, t);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, int, float, uint>)vt[459])((nint)colors, size, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImLerpU32(uint* colors, int size, float t)
		{
			uint ret = ImLerpU32Native(colors, size, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImLerpU32(ref uint colors, int size, float t)
		{
			fixed (uint* pcolors = &colors)
			{
				uint ret = ImLerpU32Native((uint*)pcolors, size, t);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ImAlphaU32Native(uint col, float alpha)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, float, uint>)vt[460])(col, alpha);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<uint, float, uint>)vt[460])(col, alpha);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ImAlphaU32(uint col, float alpha)
		{
			uint ret = ImAlphaU32Native(col, alpha);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsFloatNative(float minA, float maxA, float minB, float maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<float, float, float, float, byte>)vt[461])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<float, float, float, float, byte>)vt[461])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsFloat(float minA, float maxA, float minB, float maxB)
		{
			byte ret = ImOverlapsFloatNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsDoubleNative(double minA, double maxA, double minB, double maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double, double, double, byte>)vt[462])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<double, double, double, double, byte>)vt[462])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsDouble(double minA, double maxA, double minB, double maxB)
		{
			byte ret = ImOverlapsDoubleNative(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsS8Native(byte minA, byte maxA, byte minB, byte maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)vt[463])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)vt[463])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsS8(byte minA, byte maxA, byte minB, byte maxB)
		{
			byte ret = ImOverlapsS8Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsU8Native(byte minA, byte maxA, byte minB, byte maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)vt[464])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<byte, byte, byte, byte, byte>)vt[464])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsU8(byte minA, byte maxA, byte minB, byte maxB)
		{
			byte ret = ImOverlapsU8Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsS16Native(short minA, short maxA, short minB, short maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<short, short, short, short, byte>)vt[465])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<short, short, short, short, byte>)vt[465])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsS16(short minA, short maxA, short minB, short maxB)
		{
			byte ret = ImOverlapsS16Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsU16Native(ushort minA, ushort maxA, ushort minB, ushort maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort, byte>)vt[466])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<ushort, ushort, ushort, ushort, byte>)vt[466])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsU16(ushort minA, ushort maxA, ushort minB, ushort maxB)
		{
			byte ret = ImOverlapsU16Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsS32Native(int minA, int maxA, int minB, int maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<int, int, int, int, byte>)vt[467])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<int, int, int, int, byte>)vt[467])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsS32(int minA, int maxA, int minB, int maxB)
		{
			byte ret = ImOverlapsS32Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsU32Native(uint minA, uint maxA, uint minB, uint maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<uint, uint, uint, uint, byte>)vt[468])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<uint, uint, uint, uint, byte>)vt[468])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsU32(uint minA, uint maxA, uint minB, uint maxB)
		{
			byte ret = ImOverlapsU32Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsS64Native(long minA, long maxA, long minB, long maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long, long, long, long, byte>)vt[469])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<long, long, long, long, byte>)vt[469])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsS64(long minA, long maxA, long minB, long maxB)
		{
			byte ret = ImOverlapsS64Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ImOverlapsU64Native(ulong minA, ulong maxA, ulong minB, ulong maxB)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong, byte>)vt[470])(minA, maxA, minB, maxB);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<ulong, ulong, ulong, ulong, byte>)vt[470])(minA, maxA, minB, maxB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ImOverlapsU64(ulong minA, ulong maxA, ulong minB, ulong maxB)
		{
			byte ret = ImOverlapsU64Native(minA, maxA, minB, maxB);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotDateTimeSpec* DateTimeSpecImPlotDateTimeSpecNilNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotDateTimeSpec*>)vt[471])();
			#else
			return (ImPlotDateTimeSpec*)((delegate* unmanaged[Cdecl]<nint>)vt[471])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr DateTimeSpecImPlotDateTimeSpecNil()
		{
			ImPlotDateTimeSpecPtr ret = DateTimeSpecImPlotDateTimeSpecNilNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void DateTimeSpecDestroyNative(ImPlotDateTimeSpec* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotDateTimeSpec*, void>)vt[472])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[472])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void DateTimeSpecDestroy(ImPlotDateTimeSpecPtr self)
		{
			DateTimeSpecDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void DateTimeSpecDestroy(ref ImPlotDateTimeSpec self)
		{
			fixed (ImPlotDateTimeSpec* pself = &self)
			{
				DateTimeSpecDestroyNative((ImPlotDateTimeSpec*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotDateTimeSpec* DateTimeSpecImPlotDateTimeSpecPlotDateFmtNative(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt, byte use24HrClk, byte useIso8601)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotDateFmt, ImPlotTimeFmt, byte, byte, ImPlotDateTimeSpec*>)vt[473])(dateFmt, timeFmt, use24HrClk, useIso8601);
			#else
			return (ImPlotDateTimeSpec*)((delegate* unmanaged[Cdecl]<ImPlotDateFmt, ImPlotTimeFmt, byte, byte, nint>)vt[473])(dateFmt, timeFmt, use24HrClk, useIso8601);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotDateTimeSpecPtr DateTimeSpecImPlotDateTimeSpecPlotDateFmt(ImPlotDateFmt dateFmt, ImPlotTimeFmt timeFmt, bool use24HrClk, bool useIso8601)
		{
			ImPlotDateTimeSpecPtr ret = DateTimeSpecImPlotDateTimeSpecPlotDateFmtNative(dateFmt, timeFmt, use24HrClk ? (byte)1 : (byte)0, useIso8601 ? (byte)1 : (byte)0);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTime* TimeImPlotTimeNilNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTime*>)vt[474])();
			#else
			return (ImPlotTime*)((delegate* unmanaged[Cdecl]<nint>)vt[474])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTimePtr TimeImPlotTimeNil()
		{
			ImPlotTimePtr ret = TimeImPlotTimeNilNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TimeDestroyNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, void>)vt[475])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[475])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeDestroy(ImPlotTimePtr self)
		{
			TimeDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeDestroy(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				TimeDestroyNative((ImPlotTime*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTime* TimeImPlotTimeTimeNative(long s, int us)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<long, int, ImPlotTime*>)vt[476])(s, us);
			#else
			return (ImPlotTime*)((delegate* unmanaged[Cdecl]<long, int, nint>)vt[476])(s, us);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTimePtr TimeImPlotTimeTime(long s, int us)
		{
			ImPlotTimePtr ret = TimeImPlotTimeTimeNative(s, us);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TimeRollOverNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, void>)vt[477])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[477])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeRollOver(ImPlotTimePtr self)
		{
			TimeRollOverNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeRollOver(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				TimeRollOverNative((ImPlotTime*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double TimeToDoubleNative(ImPlotTime* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTime*, double>)vt[478])(self);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, double>)vt[478])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double TimeToDouble(ImPlotTimePtr self)
		{
			double ret = TimeToDoubleNative(self);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double TimeToDouble(ref ImPlotTime self)
		{
			fixed (ImPlotTime* pself = &self)
			{
				double ret = TimeToDoubleNative((ImPlotTime*)pself);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TimeFromDoubleNative(ImPlotTime* pOut, double t)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTime*, double, void>)vt[479])(pOut, t);
			#else
			((delegate* unmanaged[Cdecl]<nint, double, void>)vt[479])((nint)pOut, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTime TimeFromDouble(double t)
		{
			ImPlotTime ret;
			TimeFromDoubleNative(&ret, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeFromDouble(ImPlotTimePtr pOut, double t)
		{
			TimeFromDoubleNative(pOut, t);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TimeFromDouble(ref ImPlotTime pOut, double t)
		{
			fixed (ImPlotTime* ppOut = &pOut)
			{
				TimeFromDoubleNative((ImPlotTime*)ppOut, t);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotColormapData* ColormapDataImPlotColormapDataNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*>)vt[480])();
			#else
			return (ImPlotColormapData*)((delegate* unmanaged[Cdecl]<nint>)vt[480])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormapDataPtr ColormapDataImPlotColormapData()
		{
			ImPlotColormapDataPtr ret = ColormapDataImPlotColormapDataNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void ColormapDataDestroyNative(ImPlotColormapData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, void>)vt[481])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[481])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataDestroy(ImPlotColormapDataPtr self)
		{
			ColormapDataDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataDestroy(ref ImPlotColormapData self)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ColormapDataDestroyNative((ImPlotColormapData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static int ColormapDataAppendNative(ImPlotColormapData* self, byte* name, uint* keys, int count, byte qual)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, byte*, uint*, int, byte, int>)vt[482])(self, name, keys, count, qual);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, nint, nint, int, byte, int>)vt[482])((nint)self, (nint)name, (nint)keys, count, qual);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, byte* name, uint* keys, int count, bool qual)
		{
			int ret = ColormapDataAppendNative(self, name, keys, count, qual ? (byte)1 : (byte)0);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, byte* name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, name, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, ref byte name, uint* keys, int count, bool qual)
		{
			fixed (byte* pname = &name)
			{
				int ret = ColormapDataAppendNative(self, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name, uint* keys, int count, bool qual)
		{
			fixed (byte* pname = name)
			{
				int ret = ColormapDataAppendNative(self, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, string name, uint* keys, int count, bool qual)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			int ret = ColormapDataAppendNative(self, pStr0, keys, count, qual ? (byte)1 : (byte)0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, ref byte name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, ReadOnlySpan<byte> name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, (byte*)pname, keys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, string name, uint* keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, pStr0, keys, count, qual ? (byte)1 : (byte)0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, byte* name, ref uint keys, int count, bool qual)
		{
			fixed (uint* pkeys = &keys)
			{
				int ret = ColormapDataAppendNative(self, name, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, byte* name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, name, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, ref byte name, ref uint keys, int count, bool qual)
		{
			fixed (byte* pname = &name)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = ColormapDataAppendNative(self, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name, ref uint keys, int count, bool qual)
		{
			fixed (byte* pname = name)
			{
				fixed (uint* pkeys = &keys)
				{
					int ret = ColormapDataAppendNative(self, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ImPlotColormapDataPtr self, string name, ref uint keys, int count, bool qual)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			fixed (uint* pkeys = &keys)
			{
				int ret = ColormapDataAppendNative(self, pStr0, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, ref byte name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					fixed (uint* pkeys = &keys)
					{
						int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
						return ret;
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, ReadOnlySpan<byte> name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					fixed (uint* pkeys = &keys)
					{
						int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, (byte*)pname, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
						return ret;
					}
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataAppend(ref ImPlotColormapData self, string name, ref uint keys, int count, bool qual)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				fixed (uint* pkeys = &keys)
				{
					int ret = ColormapDataAppendNative((ImPlotColormapData*)pself, pStr0, (uint*)pkeys, count, qual ? (byte)1 : (byte)0);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						Utils.Free(pStr0);
					}
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void ColormapDataAppendTableNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, void>)vt[483])(self, cmap);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, void>)vt[483])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataAppendTable(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			ColormapDataAppendTableNative(self, cmap);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataAppendTable(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ColormapDataAppendTableNative((ImPlotColormapData*)pself, cmap);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void ColormapDataRebuildTablesNative(ImPlotColormapData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, void>)vt[484])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[484])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataRebuildTables(ImPlotColormapDataPtr self)
		{
			ColormapDataRebuildTablesNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataRebuildTables(ref ImPlotColormapData self)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ColormapDataRebuildTablesNative((ImPlotColormapData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte ColormapDataIsQualNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, byte>)vt[485])(self, cmap);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, byte>)vt[485])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ColormapDataIsQual(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			byte ret = ColormapDataIsQualNative(self, cmap);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool ColormapDataIsQual(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte ret = ColormapDataIsQualNative((ImPlotColormapData*)pself, cmap);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte* ColormapDataGetNameNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, byte*>)vt[486])(self, cmap);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)vt[486])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* ColormapDataGetName(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			byte* ret = ColormapDataGetNameNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string ColormapDataGetNameS(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			string ret = Utils.DecodeStringUTF8(ColormapDataGetNameNative(self, cmap));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* ColormapDataGetName(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* ret = ColormapDataGetNameNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string ColormapDataGetNameS(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(ColormapDataGetNameNative((ImPlotColormapData*)pself, cmap));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotColormap ColormapDataGetIndexNative(ImPlotColormapData* self, byte* name)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, byte*, ImPlotColormap>)vt[487])(self, name);
			#else
			return (ImPlotColormap)((delegate* unmanaged[Cdecl]<nint, nint, ImPlotColormap>)vt[487])((nint)self, (nint)name);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ImPlotColormapDataPtr self, byte* name)
		{
			ImPlotColormap ret = ColormapDataGetIndexNative(self, name);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ref ImPlotColormapData self, byte* name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ImPlotColormap ret = ColormapDataGetIndexNative((ImPlotColormapData*)pself, name);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ImPlotColormapDataPtr self, ref byte name)
		{
			fixed (byte* pname = &name)
			{
				ImPlotColormap ret = ColormapDataGetIndexNative(self, (byte*)pname);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ImPlotColormapDataPtr self, ReadOnlySpan<byte> name)
		{
			fixed (byte* pname = name)
			{
				ImPlotColormap ret = ColormapDataGetIndexNative(self, (byte*)pname);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ImPlotColormapDataPtr self, string name)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (name != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(name);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			ImPlotColormap ret = ColormapDataGetIndexNative(self, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ref ImPlotColormapData self, ref byte name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = &name)
				{
					ImPlotColormap ret = ColormapDataGetIndexNative((ImPlotColormapData*)pself, (byte*)pname);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ref ImPlotColormapData self, ReadOnlySpan<byte> name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				fixed (byte* pname = name)
				{
					ImPlotColormap ret = ColormapDataGetIndexNative((ImPlotColormapData*)pself, (byte*)pname);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotColormap ColormapDataGetIndex(ref ImPlotColormapData self, string name)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (name != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(name);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(name, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				ImPlotColormap ret = ColormapDataGetIndexNative((ImPlotColormapData*)pself, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint* ColormapDataGetKeysNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, uint*>)vt[488])(self, cmap);
			#else
			return (uint*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)vt[488])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* ColormapDataGetKeys(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			uint* ret = ColormapDataGetKeysNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* ColormapDataGetKeys(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint* ret = ColormapDataGetKeysNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static int ColormapDataGetKeyCountNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int>)vt[489])(self, cmap);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int>)vt[489])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataGetKeyCount(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			int ret = ColormapDataGetKeyCountNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataGetKeyCount(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = ColormapDataGetKeyCountNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ColormapDataGetKeyColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint>)vt[490])(self, cmap, idx);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint>)vt[490])((nint)self, cmap, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataGetKeyColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx)
		{
			uint ret = ColormapDataGetKeyColorNative(self, cmap, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataGetKeyColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = ColormapDataGetKeyColorNative((ImPlotColormapData*)pself, cmap, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void ColormapDataSetKeyColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx, uint value)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint, void>)vt[491])(self, cmap, idx, value);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint, void>)vt[491])((nint)self, cmap, idx, value);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataSetKeyColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx, uint value)
		{
			ColormapDataSetKeyColorNative(self, cmap, idx, value);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void ColormapDataSetKeyColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx, uint value)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				ColormapDataSetKeyColorNative((ImPlotColormapData*)pself, cmap, idx, value);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint* ColormapDataGetTableNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, uint*>)vt[492])(self, cmap);
			#else
			return (uint*)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, nint>)vt[492])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* ColormapDataGetTable(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			uint* ret = ColormapDataGetTableNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint* ColormapDataGetTable(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint* ret = ColormapDataGetTableNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static int ColormapDataGetTableSizeNative(ImPlotColormapData* self, ImPlotColormap cmap)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int>)vt[493])(self, cmap);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int>)vt[493])((nint)self, cmap);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataGetTableSize(ImPlotColormapDataPtr self, ImPlotColormap cmap)
		{
			int ret = ColormapDataGetTableSizeNative(self, cmap);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int ColormapDataGetTableSize(ref ImPlotColormapData self, ImPlotColormap cmap)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				int ret = ColormapDataGetTableSizeNative((ImPlotColormapData*)pself, cmap);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ColormapDataGetTableColorNative(ImPlotColormapData* self, ImPlotColormap cmap, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, int, uint>)vt[494])(self, cmap, idx);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, int, uint>)vt[494])((nint)self, cmap, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataGetTableColor(ImPlotColormapDataPtr self, ImPlotColormap cmap, int idx)
		{
			uint ret = ColormapDataGetTableColorNative(self, cmap, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataGetTableColor(ref ImPlotColormapData self, ImPlotColormap cmap, int idx)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = ColormapDataGetTableColorNative((ImPlotColormapData*)pself, cmap, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static uint ColormapDataLerpTableNative(ImPlotColormapData* self, ImPlotColormap cmap, float t)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotColormapData*, ImPlotColormap, float, uint>)vt[495])(self, cmap, t);
			#else
			return (uint)((delegate* unmanaged[Cdecl]<nint, ImPlotColormap, float, uint>)vt[495])((nint)self, cmap, t);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataLerpTable(ImPlotColormapDataPtr self, ImPlotColormap cmap, float t)
		{
			uint ret = ColormapDataLerpTableNative(self, cmap, t);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static uint ColormapDataLerpTable(ref ImPlotColormapData self, ImPlotColormap cmap, float t)
		{
			fixed (ImPlotColormapData* pself = &self)
			{
				uint ret = ColormapDataLerpTableNative((ImPlotColormapData*)pself, cmap, t);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotPointError* PointErrorImPlotPointErrorNative(double x, double y, double neg, double pos)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, double, double, double, ImPlotPointError*>)vt[496])(x, y, neg, pos);
			#else
			return (ImPlotPointError*)((delegate* unmanaged[Cdecl]<double, double, double, double, nint>)vt[496])(x, y, neg, pos);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotPointErrorPtr PointErrorImPlotPointError(double x, double y, double neg, double pos)
		{
			ImPlotPointErrorPtr ret = PointErrorImPlotPointErrorNative(x, y, neg, pos);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void PointErrorDestroyNative(ImPlotPointError* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotPointError*, void>)vt[497])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[497])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void PointErrorDestroy(ImPlotPointErrorPtr self)
		{
			PointErrorDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void PointErrorDestroy(ref ImPlotPointError self)
		{
			fixed (ImPlotPointError* pself = &self)
			{
				PointErrorDestroyNative((ImPlotPointError*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotAnnotation* AnnotationImPlotAnnotationNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotation*>)vt[498])();
			#else
			return (ImPlotAnnotation*)((delegate* unmanaged[Cdecl]<nint>)vt[498])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAnnotationPtr AnnotationImPlotAnnotation()
		{
			ImPlotAnnotationPtr ret = AnnotationImPlotAnnotationNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AnnotationDestroyNative(ImPlotAnnotation* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotation*, void>)vt[499])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[499])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationDestroy(ImPlotAnnotationPtr self)
		{
			AnnotationDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationDestroy(ref ImPlotAnnotation self)
		{
			fixed (ImPlotAnnotation* pself = &self)
			{
				AnnotationDestroyNative((ImPlotAnnotation*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotAnnotationCollection* AnnotationCollectionImPlotAnnotationCollectionNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*>)vt[500])();
			#else
			return (ImPlotAnnotationCollection*)((delegate* unmanaged[Cdecl]<nint>)vt[500])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAnnotationCollectionPtr AnnotationCollectionImPlotAnnotationCollection()
		{
			ImPlotAnnotationCollectionPtr ret = AnnotationCollectionImPlotAnnotationCollectionNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AnnotationCollectionDestroyNative(ImPlotAnnotationCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, void>)vt[501])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[501])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionDestroy(ImPlotAnnotationCollectionPtr self)
		{
			AnnotationCollectionDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionDestroy(ref ImPlotAnnotationCollection self)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AnnotationCollectionDestroyNative((ImPlotAnnotationCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AnnotationCollectionAppendVNative(ImPlotAnnotationCollection* self, Vector2 pos, Vector2 off, uint bg, uint fg, byte clamp, byte* fmt, nuint args)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, Vector2, Vector2, uint, uint, byte, byte*, nuint, void>)vt[502])(self, pos, off, bg, fg, clamp, fmt, args);
			#else
			((delegate* unmanaged[Cdecl]<nint, Vector2, Vector2, uint, uint, byte, nint, nuint, void>)vt[502])((nint)self, pos, off, bg, fg, clamp, (nint)fmt, args);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt, nuint args)
		{
			AnnotationCollectionAppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt, args);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AnnotationCollectionAppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt, nuint args)
		{
			fixed (byte* pfmt = &fmt)
			{
				AnnotationCollectionAppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (byte* pfmt = fmt)
			{
				AnnotationCollectionAppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt, nuint args)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			AnnotationCollectionAppendVNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0, args);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					AnnotationCollectionAppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					AnnotationCollectionAppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppendV(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt, nuint args)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				AnnotationCollectionAppendVNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0, args);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AnnotationCollectionAppendNative(ImPlotAnnotationCollection* self, Vector2 pos, Vector2 off, uint bg, uint fg, byte clamp, byte* fmt)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, Vector2, Vector2, uint, uint, byte, byte*, void>)vt[503])(self, pos, off, bg, fg, clamp, fmt);
			#else
			((delegate* unmanaged[Cdecl]<nint, Vector2, Vector2, uint, uint, byte, nint, void>)vt[503])((nint)self, pos, off, bg, fg, clamp, (nint)fmt);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt)
		{
			AnnotationCollectionAppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, byte* fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AnnotationCollectionAppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, fmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt)
		{
			fixed (byte* pfmt = &fmt)
			{
				AnnotationCollectionAppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt)
		{
			fixed (byte* pfmt = fmt)
			{
				AnnotationCollectionAppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ImPlotAnnotationCollectionPtr self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			AnnotationCollectionAppendNative(self, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ref byte fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					AnnotationCollectionAppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, ReadOnlySpan<byte> fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					AnnotationCollectionAppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionAppend(ref ImPlotAnnotationCollection self, Vector2 pos, Vector2 off, uint bg, uint fg, bool clamp, string fmt)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				AnnotationCollectionAppendNative((ImPlotAnnotationCollection*)pself, pos, off, bg, fg, clamp ? (byte)1 : (byte)0, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte* AnnotationCollectionGetTextNative(ImPlotAnnotationCollection* self, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, int, byte*>)vt[504])(self, idx);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, int, nint>)vt[504])((nint)self, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* AnnotationCollectionGetText(ImPlotAnnotationCollectionPtr self, int idx)
		{
			byte* ret = AnnotationCollectionGetTextNative(self, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string AnnotationCollectionGetTextS(ImPlotAnnotationCollectionPtr self, int idx)
		{
			string ret = Utils.DecodeStringUTF8(AnnotationCollectionGetTextNative(self, idx));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* AnnotationCollectionGetText(ref ImPlotAnnotationCollection self, int idx)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				byte* ret = AnnotationCollectionGetTextNative((ImPlotAnnotationCollection*)pself, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string AnnotationCollectionGetTextS(ref ImPlotAnnotationCollection self, int idx)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(AnnotationCollectionGetTextNative((ImPlotAnnotationCollection*)pself, idx));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AnnotationCollectionResetNative(ImPlotAnnotationCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAnnotationCollection*, void>)vt[505])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[505])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionReset(ImPlotAnnotationCollectionPtr self)
		{
			AnnotationCollectionResetNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AnnotationCollectionReset(ref ImPlotAnnotationCollection self)
		{
			fixed (ImPlotAnnotationCollection* pself = &self)
			{
				AnnotationCollectionResetNative((ImPlotAnnotationCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTagCollection* TagCollectionImPlotTagCollectionNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTagCollection*>)vt[506])();
			#else
			return (ImPlotTagCollection*)((delegate* unmanaged[Cdecl]<nint>)vt[506])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTagCollectionPtr TagCollectionImPlotTagCollection()
		{
			ImPlotTagCollectionPtr ret = TagCollectionImPlotTagCollectionNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TagCollectionDestroyNative(ImPlotTagCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, void>)vt[507])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[507])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionDestroy(ImPlotTagCollectionPtr self)
		{
			TagCollectionDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionDestroy(ref ImPlotTagCollection self)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				TagCollectionDestroyNative((ImPlotTagCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TagCollectionAppendVNative(ImPlotTagCollection* self, ImAxis axis, double value, uint bg, uint fg, byte* fmt, nuint args)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, ImAxis, double, uint, uint, byte*, nuint, void>)vt[508])(self, axis, value, bg, fg, fmt, args);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImAxis, double, uint, uint, nint, nuint, void>)vt[508])((nint)self, axis, value, bg, fg, (nint)fmt, args);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, byte* fmt, nuint args)
		{
			TagCollectionAppendVNative(self, axis, value, bg, fg, fmt, args);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, byte* fmt, nuint args)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				TagCollectionAppendVNative((ImPlotTagCollection*)pself, axis, value, bg, fg, fmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, ref byte fmt, nuint args)
		{
			fixed (byte* pfmt = &fmt)
			{
				TagCollectionAppendVNative(self, axis, value, bg, fg, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (byte* pfmt = fmt)
			{
				TagCollectionAppendVNative(self, axis, value, bg, fg, (byte*)pfmt, args);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, string fmt, nuint args)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			TagCollectionAppendVNative(self, axis, value, bg, fg, pStr0, args);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, ref byte fmt, nuint args)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					TagCollectionAppendVNative((ImPlotTagCollection*)pself, axis, value, bg, fg, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, ReadOnlySpan<byte> fmt, nuint args)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					TagCollectionAppendVNative((ImPlotTagCollection*)pself, axis, value, bg, fg, (byte*)pfmt, args);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppendV(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, string fmt, nuint args)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				TagCollectionAppendVNative((ImPlotTagCollection*)pself, axis, value, bg, fg, pStr0, args);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TagCollectionAppendNative(ImPlotTagCollection* self, ImAxis axis, double value, uint bg, uint fg, byte* fmt)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, ImAxis, double, uint, uint, byte*, void>)vt[509])(self, axis, value, bg, fg, fmt);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImAxis, double, uint, uint, nint, void>)vt[509])((nint)self, axis, value, bg, fg, (nint)fmt);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, byte* fmt)
		{
			TagCollectionAppendNative(self, axis, value, bg, fg, fmt);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, byte* fmt)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				TagCollectionAppendNative((ImPlotTagCollection*)pself, axis, value, bg, fg, fmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, ref byte fmt)
		{
			fixed (byte* pfmt = &fmt)
			{
				TagCollectionAppendNative(self, axis, value, bg, fg, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, ReadOnlySpan<byte> fmt)
		{
			fixed (byte* pfmt = fmt)
			{
				TagCollectionAppendNative(self, axis, value, bg, fg, (byte*)pfmt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ImPlotTagCollectionPtr self, ImAxis axis, double value, uint bg, uint fg, string fmt)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (fmt != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(fmt);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			TagCollectionAppendNative(self, axis, value, bg, fg, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, ref byte fmt)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				fixed (byte* pfmt = &fmt)
				{
					TagCollectionAppendNative((ImPlotTagCollection*)pself, axis, value, bg, fg, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, ReadOnlySpan<byte> fmt)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				fixed (byte* pfmt = fmt)
				{
					TagCollectionAppendNative((ImPlotTagCollection*)pself, axis, value, bg, fg, (byte*)pfmt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionAppend(ref ImPlotTagCollection self, ImAxis axis, double value, uint bg, uint fg, string fmt)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (fmt != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(fmt);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(fmt, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				TagCollectionAppendNative((ImPlotTagCollection*)pself, axis, value, bg, fg, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte* TagCollectionGetTextNative(ImPlotTagCollection* self, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, int, byte*>)vt[510])(self, idx);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, int, nint>)vt[510])((nint)self, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TagCollectionGetText(ImPlotTagCollectionPtr self, int idx)
		{
			byte* ret = TagCollectionGetTextNative(self, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TagCollectionGetTextS(ImPlotTagCollectionPtr self, int idx)
		{
			string ret = Utils.DecodeStringUTF8(TagCollectionGetTextNative(self, idx));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TagCollectionGetText(ref ImPlotTagCollection self, int idx)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				byte* ret = TagCollectionGetTextNative((ImPlotTagCollection*)pself, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TagCollectionGetTextS(ref ImPlotTagCollection self, int idx)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(TagCollectionGetTextNative((ImPlotTagCollection*)pself, idx));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TagCollectionResetNative(ImPlotTagCollection* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTagCollection*, void>)vt[511])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[511])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionReset(ImPlotTagCollectionPtr self)
		{
			TagCollectionResetNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TagCollectionReset(ref ImPlotTagCollection self)
		{
			fixed (ImPlotTagCollection* pself = &self)
			{
				TagCollectionResetNative((ImPlotTagCollection*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTick* TickImPlotTickNative(double value, byte major, int level, byte showLabel)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<double, byte, int, byte, ImPlotTick*>)vt[512])(value, major, level, showLabel);
			#else
			return (ImPlotTick*)((delegate* unmanaged[Cdecl]<double, byte, int, byte, nint>)vt[512])(value, major, level, showLabel);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickImPlotTick(double value, bool major, int level, bool showLabel)
		{
			ImPlotTickPtr ret = TickImPlotTickNative(value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TickDestroyNative(ImPlotTick* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTick*, void>)vt[513])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[513])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickDestroy(ImPlotTickPtr self)
		{
			TickDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickDestroy(ref ImPlotTick self)
		{
			fixed (ImPlotTick* pself = &self)
			{
				TickDestroyNative((ImPlotTick*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTicker* TickerImPlotTickerNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*>)vt[514])();
			#else
			return (ImPlotTicker*)((delegate* unmanaged[Cdecl]<nint>)vt[514])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickerPtr TickerImPlotTicker()
		{
			ImPlotTickerPtr ret = TickerImPlotTickerNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TickerDestroyNative(ImPlotTicker* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTicker*, void>)vt[515])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[515])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerDestroy(ImPlotTickerPtr self)
		{
			TickerDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerDestroy(ref ImPlotTicker self)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				TickerDestroyNative((ImPlotTicker*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTick* TickerAddTickDoubleNative(ImPlotTicker* self, double value, byte major, int level, byte showLabel, byte* label)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, double, byte, int, byte, byte*, ImPlotTick*>)vt[516])(self, value, major, level, showLabel, label);
			#else
			return (ImPlotTick*)((delegate* unmanaged[Cdecl]<nint, double, byte, int, byte, nint, nint>)vt[516])((nint)self, value, major, level, showLabel, (nint)label);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ImPlotTickerPtr self, double value, bool major, int level, bool showLabel, byte* label)
		{
			ImPlotTickPtr ret = TickerAddTickDoubleNative(self, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, label);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ref ImPlotTicker self, double value, bool major, int level, bool showLabel, byte* label)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				ImPlotTickPtr ret = TickerAddTickDoubleNative((ImPlotTicker*)pself, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, label);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ImPlotTickerPtr self, double value, bool major, int level, bool showLabel, ref byte label)
		{
			fixed (byte* plabel = &label)
			{
				ImPlotTickPtr ret = TickerAddTickDoubleNative(self, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, (byte*)plabel);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ImPlotTickerPtr self, double value, bool major, int level, bool showLabel, ReadOnlySpan<byte> label)
		{
			fixed (byte* plabel = label)
			{
				ImPlotTickPtr ret = TickerAddTickDoubleNative(self, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, (byte*)plabel);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ImPlotTickerPtr self, double value, bool major, int level, bool showLabel, string label)
		{
			byte* pStr0 = null;
			int pStrSize0 = 0;
			if (label != null)
			{
				pStrSize0 = Utils.GetByteCountUTF8(label);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
				}
				else
				{
					byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
					pStr0 = pStrStack0;
				}
				int pStrOffset0 = Utils.EncodeStringUTF8(label, pStr0, pStrSize0);
				pStr0[pStrOffset0] = 0;
			}
			ImPlotTickPtr ret = TickerAddTickDoubleNative(self, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, pStr0);
			if (pStrSize0 >= Utils.MaxStackallocSize)
			{
				Utils.Free(pStr0);
			}
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ref ImPlotTicker self, double value, bool major, int level, bool showLabel, ref byte label)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				fixed (byte* plabel = &label)
				{
					ImPlotTickPtr ret = TickerAddTickDoubleNative((ImPlotTicker*)pself, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, (byte*)plabel);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ref ImPlotTicker self, double value, bool major, int level, bool showLabel, ReadOnlySpan<byte> label)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				fixed (byte* plabel = label)
				{
					ImPlotTickPtr ret = TickerAddTickDoubleNative((ImPlotTicker*)pself, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, (byte*)plabel);
					return ret;
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDouble(ref ImPlotTicker self, double value, bool major, int level, bool showLabel, string label)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				byte* pStr0 = null;
				int pStrSize0 = 0;
				if (label != null)
				{
					pStrSize0 = Utils.GetByteCountUTF8(label);
					if (pStrSize0 >= Utils.MaxStackallocSize)
					{
						pStr0 = Utils.Alloc<byte>(pStrSize0 + 1);
					}
					else
					{
						byte* pStrStack0 = stackalloc byte[pStrSize0 + 1];
						pStr0 = pStrStack0;
					}
					int pStrOffset0 = Utils.EncodeStringUTF8(label, pStr0, pStrSize0);
					pStr0[pStrOffset0] = 0;
				}
				ImPlotTickPtr ret = TickerAddTickDoubleNative((ImPlotTicker*)pself, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, pStr0);
				if (pStrSize0 >= Utils.MaxStackallocSize)
				{
					Utils.Free(pStr0);
				}
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTick* TickerAddTickDoublePlotFormatterNative(ImPlotTicker* self, double value, byte major, int level, byte showLabel, ImPlotFormatter formatter, void* data)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, double, byte, int, byte, delegate*<double, byte*, int, void*, int>, void*, ImPlotTick*>)vt[517])(self, value, major, level, showLabel, (delegate*<double, byte*, int, void*, int>)Utils.GetFunctionPointerForDelegate(formatter), data);
			#else
			return (ImPlotTick*)((delegate* unmanaged[Cdecl]<nint, double, byte, int, byte, nint, nint, nint>)vt[517])((nint)self, value, major, level, showLabel, (nint)Utils.GetFunctionPointerForDelegate(formatter), (nint)data);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDoublePlotFormatter(ImPlotTickerPtr self, double value, bool major, int level, bool showLabel, ImPlotFormatter formatter, void* data)
		{
			ImPlotTickPtr ret = TickerAddTickDoublePlotFormatterNative(self, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, formatter, data);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickDoublePlotFormatter(ref ImPlotTicker self, double value, bool major, int level, bool showLabel, ImPlotFormatter formatter, void* data)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				ImPlotTickPtr ret = TickerAddTickDoublePlotFormatterNative((ImPlotTicker*)pself, value, major ? (byte)1 : (byte)0, level, showLabel ? (byte)1 : (byte)0, formatter, data);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotTick* TickerAddTickPlotTickNative(ImPlotTicker* self, ImPlotTick tick)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, ImPlotTick, ImPlotTick*>)vt[518])(self, tick);
			#else
			return (ImPlotTick*)((delegate* unmanaged[Cdecl]<nint, ImPlotTick, nint>)vt[518])((nint)self, tick);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickPlotTick(ImPlotTickerPtr self, ImPlotTick tick)
		{
			ImPlotTickPtr ret = TickerAddTickPlotTickNative(self, tick);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotTickPtr TickerAddTickPlotTick(ref ImPlotTicker self, ImPlotTick tick)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				ImPlotTickPtr ret = TickerAddTickPlotTickNative((ImPlotTicker*)pself, tick);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte* TickerGetTextIntNative(ImPlotTicker* self, int idx)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, int, byte*>)vt[519])(self, idx);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, int, nint>)vt[519])((nint)self, idx);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TickerGetTextInt(ImPlotTickerPtr self, int idx)
		{
			byte* ret = TickerGetTextIntNative(self, idx);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TickerGetTextIntS(ImPlotTickerPtr self, int idx)
		{
			string ret = Utils.DecodeStringUTF8(TickerGetTextIntNative(self, idx));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TickerGetTextInt(ref ImPlotTicker self, int idx)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				byte* ret = TickerGetTextIntNative((ImPlotTicker*)pself, idx);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TickerGetTextIntS(ref ImPlotTicker self, int idx)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(TickerGetTextIntNative((ImPlotTicker*)pself, idx));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte* TickerGetTextPlotTickNative(ImPlotTicker* self, ImPlotTick tick)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, ImPlotTick, byte*>)vt[520])(self, tick);
			#else
			return (byte*)((delegate* unmanaged[Cdecl]<nint, ImPlotTick, nint>)vt[520])((nint)self, tick);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TickerGetTextPlotTick(ImPlotTickerPtr self, ImPlotTick tick)
		{
			byte* ret = TickerGetTextPlotTickNative(self, tick);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TickerGetTextPlotTickS(ImPlotTickerPtr self, ImPlotTick tick)
		{
			string ret = Utils.DecodeStringUTF8(TickerGetTextPlotTickNative(self, tick));
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static byte* TickerGetTextPlotTick(ref ImPlotTicker self, ImPlotTick tick)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				byte* ret = TickerGetTextPlotTickNative((ImPlotTicker*)pself, tick);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static string TickerGetTextPlotTickS(ref ImPlotTicker self, ImPlotTick tick)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				string ret = Utils.DecodeStringUTF8(TickerGetTextPlotTickNative((ImPlotTicker*)pself, tick));
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TickerOverrideSizeLateNative(ImPlotTicker* self, Vector2 size)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTicker*, Vector2, void>)vt[521])(self, size);
			#else
			((delegate* unmanaged[Cdecl]<nint, Vector2, void>)vt[521])((nint)self, size);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerOverrideSizeLate(ImPlotTickerPtr self, Vector2 size)
		{
			TickerOverrideSizeLateNative(self, size);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerOverrideSizeLate(ref ImPlotTicker self, Vector2 size)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				TickerOverrideSizeLateNative((ImPlotTicker*)pself, size);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void TickerResetNative(ImPlotTicker* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotTicker*, void>)vt[522])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[522])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerReset(ImPlotTickerPtr self)
		{
			TickerResetNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void TickerReset(ref ImPlotTicker self)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				TickerResetNative((ImPlotTicker*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static int TickerTickCountNative(ImPlotTicker* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotTicker*, int>)vt[523])(self);
			#else
			return (int)((delegate* unmanaged[Cdecl]<nint, int>)vt[523])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int TickerTickCount(ImPlotTickerPtr self)
		{
			int ret = TickerTickCountNative(self);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static int TickerTickCount(ref ImPlotTicker self)
		{
			fixed (ImPlotTicker* pself = &self)
			{
				int ret = TickerTickCountNative((ImPlotTicker*)pself);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotAxis* AxisImPlotAxisNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*>)vt[524])();
			#else
			return (ImPlotAxis*)((delegate* unmanaged[Cdecl]<nint>)vt[524])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAxisPtr AxisImPlotAxis()
		{
			ImPlotAxisPtr ret = AxisImPlotAxisNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisDestroyNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[525])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[525])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisDestroy(ImPlotAxisPtr self)
		{
			AxisDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisDestroy(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisDestroyNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisResetNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[526])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[526])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisReset(ImPlotAxisPtr self)
		{
			AxisResetNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisReset(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisResetNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisSetMinNative(ImPlotAxis* self, double min, byte force)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, byte, byte>)vt[527])(self, min, force);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, double, byte, byte>)vt[527])((nint)self, min, force);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisSetMin(ImPlotAxisPtr self, double min, bool force)
		{
			byte ret = AxisSetMinNative(self, min, force ? (byte)1 : (byte)0);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisSetMin(ref ImPlotAxis self, double min, bool force)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisSetMinNative((ImPlotAxis*)pself, min, force ? (byte)1 : (byte)0);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisSetMaxNative(ImPlotAxis* self, double max, byte force)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, byte, byte>)vt[528])(self, max, force);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, double, byte, byte>)vt[528])((nint)self, max, force);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisSetMax(ImPlotAxisPtr self, double max, bool force)
		{
			byte ret = AxisSetMaxNative(self, max, force ? (byte)1 : (byte)0);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisSetMax(ref ImPlotAxis self, double max, bool force)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisSetMaxNative((ImPlotAxis*)pself, max, force ? (byte)1 : (byte)0);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisSetRangeDoubleNative(ImPlotAxis* self, double v1, double v2)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, double, void>)vt[529])(self, v1, v2);
			#else
			((delegate* unmanaged[Cdecl]<nint, double, double, void>)vt[529])((nint)self, v1, v2);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetRangeDouble(ImPlotAxisPtr self, double v1, double v2)
		{
			AxisSetRangeDoubleNative(self, v1, v2);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetRangeDouble(ref ImPlotAxis self, double v1, double v2)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisSetRangeDoubleNative((ImPlotAxis*)pself, v1, v2);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisSetRangePlotRangeNative(ImPlotAxis* self, ImPlotRange range)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, ImPlotRange, void>)vt[530])(self, range);
			#else
			((delegate* unmanaged[Cdecl]<nint, ImPlotRange, void>)vt[530])((nint)self, range);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetRangePlotRange(ImPlotAxisPtr self, ImPlotRange range)
		{
			AxisSetRangePlotRangeNative(self, range);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetRangePlotRange(ref ImPlotAxis self, ImPlotRange range)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisSetRangePlotRangeNative((ImPlotAxis*)pself, range);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisSetAspectNative(ImPlotAxis* self, double unitPerPix)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, void>)vt[531])(self, unitPerPix);
			#else
			((delegate* unmanaged[Cdecl]<nint, double, void>)vt[531])((nint)self, unitPerPix);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetAspect(ImPlotAxisPtr self, double unitPerPix)
		{
			AxisSetAspectNative(self, unitPerPix);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisSetAspect(ref ImPlotAxis self, double unitPerPix)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisSetAspectNative((ImPlotAxis*)pself, unitPerPix);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static float AxisPixelSizeNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, float>)vt[532])(self);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, float>)vt[532])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float AxisPixelSize(ImPlotAxisPtr self)
		{
			float ret = AxisPixelSizeNative(self);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float AxisPixelSize(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				float ret = AxisPixelSizeNative((ImPlotAxis*)pself);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double AxisGetAspectNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, double>)vt[533])(self);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, double>)vt[533])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double AxisGetAspect(ImPlotAxisPtr self)
		{
			double ret = AxisGetAspectNative(self);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double AxisGetAspect(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				double ret = AxisGetAspectNative((ImPlotAxis*)pself);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisConstrainNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[534])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[534])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisConstrain(ImPlotAxisPtr self)
		{
			AxisConstrainNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisConstrain(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisConstrainNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisUpdateTransformCacheNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[535])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[535])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisUpdateTransformCache(ImPlotAxisPtr self)
		{
			AxisUpdateTransformCacheNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisUpdateTransformCache(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisUpdateTransformCacheNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static float AxisPlotToPixelsNative(ImPlotAxis* self, double plt)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, float>)vt[536])(self, plt);
			#else
			return (float)((delegate* unmanaged[Cdecl]<nint, double, float>)vt[536])((nint)self, plt);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float AxisPlotToPixels(ImPlotAxisPtr self, double plt)
		{
			float ret = AxisPlotToPixelsNative(self, plt);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static float AxisPlotToPixels(ref ImPlotAxis self, double plt)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				float ret = AxisPlotToPixelsNative((ImPlotAxis*)pself, plt);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static double AxisPixelsToPlotNative(ImPlotAxis* self, float pix)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, float, double>)vt[537])(self, pix);
			#else
			return (double)((delegate* unmanaged[Cdecl]<nint, float, double>)vt[537])((nint)self, pix);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double AxisPixelsToPlot(ImPlotAxisPtr self, float pix)
		{
			double ret = AxisPixelsToPlotNative(self, pix);
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static double AxisPixelsToPlot(ref ImPlotAxis self, float pix)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				double ret = AxisPixelsToPlotNative((ImPlotAxis*)pself, pix);
				return ret;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisExtendFitNative(ImPlotAxis* self, double v)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, double, void>)vt[538])(self, v);
			#else
			((delegate* unmanaged[Cdecl]<nint, double, void>)vt[538])((nint)self, v);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFit(ImPlotAxisPtr self, double v)
		{
			AxisExtendFitNative(self, v);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFit(ref ImPlotAxis self, double v)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisExtendFitNative((ImPlotAxis*)pself, v);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisExtendFitWithNative(ImPlotAxis* self, ImPlotAxis* alt, double v, double vAlt)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, ImPlotAxis*, double, double, void>)vt[539])(self, alt, v, vAlt);
			#else
			((delegate* unmanaged[Cdecl]<nint, nint, double, double, void>)vt[539])((nint)self, (nint)alt, v, vAlt);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFitWith(ImPlotAxisPtr self, ImPlotAxisPtr alt, double v, double vAlt)
		{
			AxisExtendFitWithNative(self, alt, v, vAlt);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFitWith(ref ImPlotAxis self, ImPlotAxisPtr alt, double v, double vAlt)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisExtendFitWithNative((ImPlotAxis*)pself, alt, v, vAlt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFitWith(ImPlotAxisPtr self, ref ImPlotAxis alt, double v, double vAlt)
		{
			fixed (ImPlotAxis* palt = &alt)
			{
				AxisExtendFitWithNative(self, (ImPlotAxis*)palt, v, vAlt);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisExtendFitWith(ref ImPlotAxis self, ref ImPlotAxis alt, double v, double vAlt)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				fixed (ImPlotAxis* palt = &alt)
				{
					AxisExtendFitWithNative((ImPlotAxis*)pself, (ImPlotAxis*)palt, v, vAlt);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisApplyFitNative(ImPlotAxis* self, float padding)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, float, void>)vt[540])(self, padding);
			#else
			((delegate* unmanaged[Cdecl]<nint, float, void>)vt[540])((nint)self, padding);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisApplyFit(ImPlotAxisPtr self, float padding)
		{
			AxisApplyFitNative(self, padding);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisApplyFit(ref ImPlotAxis self, float padding)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisApplyFitNative((ImPlotAxis*)pself, padding);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisHasLabelNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[541])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[541])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasLabel(ImPlotAxisPtr self)
		{
			byte ret = AxisHasLabelNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasLabel(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisHasLabelNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisHasGridLinesNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[542])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[542])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasGridLines(ImPlotAxisPtr self)
		{
			byte ret = AxisHasGridLinesNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasGridLines(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisHasGridLinesNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisHasTickLabelsNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[543])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[543])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasTickLabels(ImPlotAxisPtr self)
		{
			byte ret = AxisHasTickLabelsNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasTickLabels(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisHasTickLabelsNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisHasTickMarksNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[544])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[544])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasTickMarks(ImPlotAxisPtr self)
		{
			byte ret = AxisHasTickMarksNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasTickMarks(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisHasTickMarksNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisWillRenderNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[545])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[545])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisWillRender(ImPlotAxisPtr self)
		{
			byte ret = AxisWillRenderNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisWillRender(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisWillRenderNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsOppositeNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[546])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[546])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsOpposite(ImPlotAxisPtr self)
		{
			byte ret = AxisIsOppositeNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsOpposite(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsOppositeNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsInvertedNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[547])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[547])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInverted(ImPlotAxisPtr self)
		{
			byte ret = AxisIsInvertedNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInverted(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsInvertedNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsForegroundNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[548])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[548])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsForeground(ImPlotAxisPtr self)
		{
			byte ret = AxisIsForegroundNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsForeground(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsForegroundNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsAutoFittingNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[549])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[549])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsAutoFitting(ImPlotAxisPtr self)
		{
			byte ret = AxisIsAutoFittingNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsAutoFitting(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsAutoFittingNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisCanInitFitNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[550])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[550])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisCanInitFit(ImPlotAxisPtr self)
		{
			byte ret = AxisCanInitFitNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisCanInitFit(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisCanInitFitNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsRangeLockedNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[551])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[551])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsRangeLocked(ImPlotAxisPtr self)
		{
			byte ret = AxisIsRangeLockedNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsRangeLocked(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsRangeLockedNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsLockedMinNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[552])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[552])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLockedMin(ImPlotAxisPtr self)
		{
			byte ret = AxisIsLockedMinNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLockedMin(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsLockedMinNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsLockedMaxNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[553])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[553])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLockedMax(ImPlotAxisPtr self)
		{
			byte ret = AxisIsLockedMaxNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLockedMax(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsLockedMaxNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsLockedNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[554])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[554])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLocked(ImPlotAxisPtr self)
		{
			byte ret = AxisIsLockedNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsLocked(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsLockedNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsInputLockedMinNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[555])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[555])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLockedMin(ImPlotAxisPtr self)
		{
			byte ret = AxisIsInputLockedMinNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLockedMin(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsInputLockedMinNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsInputLockedMaxNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[556])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[556])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLockedMax(ImPlotAxisPtr self)
		{
			byte ret = AxisIsInputLockedMaxNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLockedMax(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsInputLockedMaxNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsInputLockedNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[557])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[557])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLocked(ImPlotAxisPtr self)
		{
			byte ret = AxisIsInputLockedNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsInputLocked(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsInputLockedNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisHasMenusNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte>)vt[558])(self);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte>)vt[558])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasMenus(ImPlotAxisPtr self)
		{
			byte ret = AxisHasMenusNative(self);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisHasMenus(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisHasMenusNative((ImPlotAxis*)pself);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static byte AxisIsPanLockedNative(ImPlotAxis* self, byte increasing)
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAxis*, byte, byte>)vt[559])(self, increasing);
			#else
			return (byte)((delegate* unmanaged[Cdecl]<nint, byte, byte>)vt[559])((nint)self, increasing);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsPanLocked(ImPlotAxisPtr self, bool increasing)
		{
			byte ret = AxisIsPanLockedNative(self, increasing ? (byte)1 : (byte)0);
			return ret != 0;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static bool AxisIsPanLocked(ref ImPlotAxis self, bool increasing)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				byte ret = AxisIsPanLockedNative((ImPlotAxis*)pself, increasing ? (byte)1 : (byte)0);
				return ret != 0;
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisPushLinksNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[560])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[560])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisPushLinks(ImPlotAxisPtr self)
		{
			AxisPushLinksNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisPushLinks(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisPushLinksNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AxisPullLinksNative(ImPlotAxis* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAxis*, void>)vt[561])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[561])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisPullLinks(ImPlotAxisPtr self)
		{
			AxisPullLinksNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AxisPullLinks(ref ImPlotAxis self)
		{
			fixed (ImPlotAxis* pself = &self)
			{
				AxisPullLinksNative((ImPlotAxis*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static ImPlotAlignmentData* AlignmentDataImPlotAlignmentDataNative()
		{
			#if NET5_0_OR_GREATER
			return ((delegate* unmanaged[Cdecl]<ImPlotAlignmentData*>)vt[562])();
			#else
			return (ImPlotAlignmentData*)((delegate* unmanaged[Cdecl]<nint>)vt[562])();
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static ImPlotAlignmentDataPtr AlignmentDataImPlotAlignmentData()
		{
			ImPlotAlignmentDataPtr ret = AlignmentDataImPlotAlignmentDataNative();
			return ret;
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AlignmentDataDestroyNative(ImPlotAlignmentData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAlignmentData*, void>)vt[563])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[563])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataDestroy(ImPlotAlignmentDataPtr self)
		{
			AlignmentDataDestroyNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataDestroy(ref ImPlotAlignmentData self)
		{
			fixed (ImPlotAlignmentData* pself = &self)
			{
				AlignmentDataDestroyNative((ImPlotAlignmentData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AlignmentDataBeginNative(ImPlotAlignmentData* self)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAlignmentData*, void>)vt[564])(self);
			#else
			((delegate* unmanaged[Cdecl]<nint, void>)vt[564])((nint)self);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataBegin(ImPlotAlignmentDataPtr self)
		{
			AlignmentDataBeginNative(self);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataBegin(ref ImPlotAlignmentData self)
		{
			fixed (ImPlotAlignmentData* pself = &self)
			{
				AlignmentDataBeginNative((ImPlotAlignmentData*)pself);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		internal static void AlignmentDataUpdateNative(ImPlotAlignmentData* self, float* padA, float* padB, float* deltaA, float* deltaB)
		{
			#if NET5_0_OR_GREATER
			((delegate* unmanaged[Cdecl]<ImPlotAlignmentData*, float*, float*, float*, float*, void>)vt[565])(self, padA, padB, deltaA, deltaB);
			#else
			((delegate* unmanaged[Cdecl]<nint, nint, nint, nint, nint, void>)vt[565])((nint)self, (nint)padA, (nint)padB, (nint)deltaA, (nint)deltaB);
			#endif
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ImPlotAlignmentDataPtr self, float* padA, float* padB, float* deltaA, float* deltaB)
		{
			AlignmentDataUpdateNative(self, padA, padB, deltaA, deltaB);
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ref ImPlotAlignmentData self, float* padA, float* padB, float* deltaA, float* deltaB)
		{
			fixed (ImPlotAlignmentData* pself = &self)
			{
				AlignmentDataUpdateNative((ImPlotAlignmentData*)pself, padA, padB, deltaA, deltaB);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ImPlotAlignmentDataPtr self, ref float padA, float* padB, float* deltaA, float* deltaB)
		{
			fixed (float* ppadA = &padA)
			{
				AlignmentDataUpdateNative(self, (float*)ppadA, padB, deltaA, deltaB);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ref ImPlotAlignmentData self, ref float padA, float* padB, float* deltaA, float* deltaB)
		{
			fixed (ImPlotAlignmentData* pself = &self)
			{
				fixed (float* ppadA = &padA)
				{
					AlignmentDataUpdateNative((ImPlotAlignmentData*)pself, (float*)ppadA, padB, deltaA, deltaB);
				}
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ImPlotAlignmentDataPtr self, float* padA, ref float padB, float* deltaA, float* deltaB)
		{
			fixed (float* ppadB = &padB)
			{
				AlignmentDataUpdateNative(self, padA, (float*)ppadB, deltaA, deltaB);
			}
		}

		/// <summary>
		/// To be documented.
		/// </summary>
		public static void AlignmentDataUpdate(ref ImPlotAlignmentData self, float* padA, ref float padB, float* deltaA, float* deltaB)
		{
			fixed (ImPlotAlignmentData* pself = &self)
			{
				fixed (float* ppadB = &padB)
				{
					AlignmentDataUpdateNative((ImPlotAlignmentData*)pself, padA, (float*)ppadB, deltaA, deltaB);
				}
			}
		}
	}
}
